### Alexander Barquero & Anisha Wadhwani
# Project #1: Part 2: Online/Live Recognition
### CIS6930: HCIRA

# Introduction
We present our implementation of the $1 Recognizer, based on the work done by Wobbrock, Wilson and Li.
In this Part 2, we implement the Live version of the $1 Recognizer. It stores templates, collects points, executes the algorithm to compare, and outputs results.

# System
The application was developed using the Java language, specifically with the Java Standard Edition 18 SDK. 
Implementation was done in Microsoft Visual Studio Code, which is a simple but powerful solution that supports all the necessary IDE features that our team requires for this particular endeavor.
We use a Github repository for source code version control.

# User Guide
- The user can click with his mouse anywhere inside the canvas, and the system will capture the mouse press and start drawing.
- The system will continue drawing until the user releases the mouse press.
- When the user releases the mouse press, the system will execute the recognition algorithm, matching the drawing to the known templates.
- The system will display the figure identified by the recognizer, as well as the score that it obtained.
- The user can draw additional objects.
- The user can click on the Clear button to clear the screen.
- The user can click on the X button in the corner to close the application.

# Instalation and Execution

You can run the system from any Java enabled IDE, by using the standard running functionalities. As usual, make sure you have Java compiling and runtime capabilities in your computer.

If you want to run from a console, you also need to make sure you have Java compiling and runtime capabilities in your computer. Once that is done, please navigate to the folder root where the .java files are located, and execute the following commands in order:  

```sh
javac DollarRecognizer.java
java DollarRecognizer
```

# Application Features

- Second version adequately running on a Java environment.
- Blank canvas shown when executed.
- User can draw in the canvas with their mouse, and the strokes will be displayed accordingly.
- System will execute the $1 algorithm and inform the user of the best match to their gesture based on known templates. 
- Includes a Clear button that cleans the screen for the user.

# Goals and Coding Features

## Part 2

## a) store the points generated by the mouse or touch events on your canvas 
### Method mouseDragged (line 52)
Added the functionality on mousedragged, to store each point as it is being drawn on canvas (plus the first point that is drawn on mousePressed).
Points are stored on an ArrayList that grows dinamically depending on the user speed and stroke size.

## b) store a default set of templates to compare new candidate (input) gestures to 
### Method generateTemplates (line 359)
Populates the internal list of unistroke templates with preexisting 16 templates.
Templates are then processed with the $1 algorithm in (line 352).
Processed templates can now be used to compare the user gesture.

## c) implement the $1 recognition algorithm and call it when a gesture is drawn  
### Method mouseReleased (line 68)
When the user finishes drawing the gesture, the method calls the points list processing and recognition.
### Method processingGesture (line 110)
Orchestrator method that calls each one of the four steps of the $1 recognizer sequentially.
### Method resample (line 129)
Resamples the X,Y point representation of the drawn gesture from the original count to a total of 64 points.
### Method rotateToZero (line 179)
Rotates the resampled gesture to a new angle using the gesture centroid as the pivot anchor.
### Method scaleToSquare (line 208)
Establishes the bounding box around the resampled and rotated gesture, and scales it to fit the margins.
### Method translateToOrigin (line 239)
Shifts all the the gesture points towards an origin position based on the centroid.
### Method recognize (line 253)
Compares the resampled, rotated, scaled and translated gesture to the processed templates, and creates a hashmap with all the scores for each template.

`
`
`
NEED TO VERIFY THIS WITH ANISHA, the HASHMAP





## d) output the result of the recognition call to the GUI onscreen
### Method mouseReleased (line 68)
When the recognition process finishes, the method modifies and shows the text of the result label that displays the best matching template and the related score.

## Part 1

## a) set up your project development environment - DollarRecognizer.java in Visual Studio Code 

## b) instantiate a blank ‘canvas’ to the screen using GUI elements
### Class CanvasPanel (line 10)
Creates the canvas that will be used to draw the gesture. Also holds the mouse interaction events.
### Class DollarRecognizer (line 72)
Main class for our system. It invokes the CanvasPanel to create the canvas, centers the canvas on screen, and generates the button that can clear the screen when clicked by the user.

## c) listen for mouse or touch events on the canvas and draw them as the user makes them 
### Method mousePressed (line 25)
Activates when the mouse button is initially pressed. Creates a single red point to mark the stroke starting point, and activates a system flag that informs the drag method that the mouse has been pressed so as to continue the line drawing.
### Method mouseDragged (line 40)
Activates when the mouse is dragged. If the mouse pressed flag is activated, it extends the current stroke to include both the new and previous registered X,Y point in the canvas.
### Method mouseReleased (line 56)
Activates when the mouse button is released. It deactivates the flag.

## d) allow the user to clear the canvas 
### Method setButtons (line 92)
Generates the button that can clear the screen when clicked by the user, and locates it in the lower middle section of the screen.

# License
MIT

